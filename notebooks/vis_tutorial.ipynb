{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIS Tutorial \n",
    "\n",
    "When starting an image-based phenotyping project it is important to consider what the end goals of the project are.\n",
    "This is important because the goals of the project will determine the the camera type, imaging layout, and will help to \n",
    "guide downstream analysis. For example, if the goal of the project is to quantify the growth rates of a population of \n",
    "Arabidopsis plants, you may want to take timelapse images of whole flats of plants with an RGB (VIS) camera.\n",
    "\n",
    "To run a VIS pipeline over a single VIS image there are two required inputs:\n",
    "\n",
    "1.  **Image:** Images can be processed regardless of what type of VIS camera was used (high-throughput platform, digital camera, cell phone camera).\n",
    "Image processing will work with adjustments if images are well lit and free of background that is similar in color to plant material.  \n",
    "2.  **Output directory:** If debug mode is set to 'print' output images from each step are produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import PlantCV \n",
    "from plantcv import plantcv as pcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class options:\n",
    "    def __init__(self):\n",
    "        self.image = \"img/tutorial_images/vis/original_image.jpg\"\n",
    "        self.debug = \"plot\"\n",
    "        self.writeimg= False\n",
    "        self.result = \"./vis_tutorial_results\"\n",
    "        self.outdir = \".\"\n",
    "        \n",
    "# Get options\n",
    "args = options()\n",
    "\n",
    "# Set debug to the global parameter \n",
    "pcv.params.debug = args.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "img, path, filename = pcv.readimage(args.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert RGB to HSV and extract the saturation channel\n",
    "\n",
    "# Inputs:\n",
    "#   rgb_image - RGB image data \n",
    "#   channel - Split by 'h' (hue), 's' (saturation), or 'v' (value) channel\n",
    "s = pcv.rgb2gray_hsv(img, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold can be on either light or dark objects in the image. \n",
    "\n",
    "# Inputs:\n",
    "#   gray_img - Grayscale image data \n",
    "#   threshold- Threshold value (between 0-255)\n",
    "#   max_value - Value to apply above threshold (255 = white) \n",
    "#   object_type - 'light' (default) or 'dark'. If the object is lighter than the background then standard threshold is done.\n",
    "#                 If the object is darker than the background then inverse thresholding is done. \n",
    "s_thresh = pcv.threshold.binary(s, 85, 255, 'light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Blur \n",
    "\n",
    "# Inputs: \n",
    "#   gray_img - Grayscale image data \n",
    "#   ksize - Kernel size (integer or tuple), (ksize, ksize) box if integer input,\n",
    "#           (n, m) box if tuple input \n",
    "s_mblur = pcv.median_blur(s_thresh, 5)\n",
    "s_cnt = pcv.median_blur(s_thresh, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative to using median_blur is gaussian_blur, which applies \n",
    "# a gaussian blur filter to the image. Depending on the image, one \n",
    "# technique may be more effective than others. \n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data\n",
    "#   ksize - Tuple of kernel size\n",
    "#   sigmax - Standard deviation in X direction; if 0 (default), \n",
    "#            calculated from kernel size\n",
    "#   sigmay - Standard deviation in Y direction; if sigmaY is \n",
    "#            None (default), sigmaY is taken to equal sigmaX\n",
    "gaussian_img = pcv.gaussian_blur(img=s_thresh, ksize=(5, 5), sigmax=0, sigmay=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB to LAB and extract the blue channel ('b')\n",
    "\n",
    "# Input:\n",
    "#   rgb_img - RGB image data \n",
    "#   channel- Split by 'l' (lightness), 'a' (green-magenta), or 'b' (blue-yellow) channel\n",
    "b = pcv.rgb2gray_lab(img, 'b')\n",
    "\n",
    "# Threshold the blue channel image \n",
    "\n",
    "b_thresh = pcv.threshold.binary(b, 160, 255, 'light')\n",
    "b_cnt = pcv.threshold.binary(b, 160, 255, 'light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the threshold saturation and blue-yellow images\n",
    "\n",
    "# Inputs: \n",
    "#   bin_img1 - Binary image data to be compared to bin_img2\n",
    "#   bin_img2 - Binary image data to be compared to bin_img1\n",
    "bs = pcv.logical_or(s_mblur, b_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appy Mask (for VIS images, mask_color='white')\n",
    "\n",
    "# Inputs:\n",
    "#   rgb_img - RGB image data \n",
    "#   mask - Binary mask image data \n",
    "#   mask_color - 'white' or 'black' \n",
    "masked = pcv.apply_mask(img, bs, 'white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll focus on capturing the plant in the masked image. We will use masked green-magenta and blue-yellow channels. \n",
    "Then two channels are thresholded to caputre different portions of the plant, and thre three images are joined together. \n",
    "Small objected are filled, and the resulting binary image is used to mask the masked image previously obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB to LAB and extract the Green-Magenta and Blue-Yellow channels\n",
    "\n",
    "masked_a = pcv.rgb2gray_lab(masked, 'a')\n",
    "masked_b = pcv.rgb2gray_lab(masked, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the green-magenta and blue images\n",
    "\n",
    "maskeda_thresh = pcv.threshold.binary(masked_a, 115, 255, 'dark')\n",
    "maskeda_thresh1 = pcv.threshold.binary(masked_a, 135, 255, 'light')\n",
    "maskedb_thresh = pcv.threshold.binary(masked_b, 128, 255, 'light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the thresholded saturation and blue-yellow images (OR)\n",
    "\n",
    "ab1 = pcv.logical_or(maskeda_thresh, maskedb_thresh)\n",
    "ab = pcv.logical_or(maskeda_thresh1, ab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the situation it might be useful to use the \n",
    "# exclusive or (pcv.logical_xor) function. \n",
    "\n",
    "# Inputs: \n",
    "#   bin_img1 - Binary image data to be compared to bin_img2\n",
    "#   bin_img2 - Binary image data to be compared to bin_img1\n",
    "xor_img = pcv.logical_xor(maskeda_thresh, maskedb_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill small objects (reduce image noise) \n",
    "\n",
    "# Inputs: \n",
    "#   bin_img - Binary image data \n",
    "#   size - Minimum object area size in pixels (must be an integer), and smaller objects will be filled\n",
    "ab_fill = pcv.fill(ab, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mask (for VIS images, mask_color=white)\n",
    "\n",
    "masked2 = pcv.apply_mask(masked, ab_fill, 'white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to identify the objects (also called contours) within the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify objects\n",
    "\n",
    "# Inputs: \n",
    "#   img - RGB or grayscale image data for plotting \n",
    "#   mask - Binary mask used for detecting contours \n",
    "id_objects, obj_hierarchy = pcv.find_objects(masked2, ab_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the region of interest (ROI) \n",
    "\n",
    "# Inputs: \n",
    "#   x - The x-coordinate of the upper left corner of the rectangle \n",
    "#   y - The y-coordinate of the upper left corner of the rectangle \n",
    "#   h - The height of the rectangle \n",
    "#   w - The width of the rectangle \n",
    "#   img - RGB or grayscale image to plot the ROI on \n",
    "roi1, roi_hierarchy= pcv.roi.rectangle(x=100, y=100, h=200, w=200, img=masked2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which objects to keep\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data to display kept objects on \n",
    "#   roi_type - 'cutto' or 'partial' => include objects that are partially inside or overlapping with the ROI \n",
    "#   roi_contour - contour of ROI, output from pcv.roi.rectangle in this case\n",
    "#   object_contour - Contour of objects, output from pcv.roi.rectangle in this case \n",
    "#   obj_hierarchy - Hierarchy of objects, output from pcv.find_objects function \n",
    "roi_objects, hierarchy3, kept_mask, obj_area = pcv.roi_objects(img, 'partial', roi1, roi_hierarchy, id_objects, obj_hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object combine kept objects\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data for plotting \n",
    "#   contours - Contour list \n",
    "#   hierarchy - Contour hierarchy array \n",
    "obj, mask = pcv.object_composition(img, roi_objects, hierarchy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to analyze the plant object for traits such as horizontal height, shape, or color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Analysis ################ \n",
    "  \n",
    "# Find shape properties, output shape image (optional)\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   obj- Single or grouped contour object\n",
    "#   mask - Binary image mask to use as mask for moments analysis \n",
    "# Returns:\n",
    "#   shape_header, shape_data, and analysis_images (an array containing the original image with shape\n",
    "#   data plotted on it, and the mask) \n",
    "shape_header, shape_data, analysis_images = pcv.analyze_object(img, obj, mask)\n",
    "\n",
    "# analysis_images contains two images, the original image with shape data drawn on, and the mask\n",
    "shape_info_img, shape_mask = analysis_images\n",
    "# Plot them out \n",
    "pcv.plot_image(shape_info_img)\n",
    "pcv.plot_image(shape_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape properties relative to user boundary line (optional)\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   obj - Single or grouped contour object \n",
    "#   mask - Binary mask of selected contours \n",
    "#   line_position - Position of boundary line (a value of 0 would draw a line \n",
    "#                   through the bottom of the image) \n",
    "boundary_header, boundary_data, boundary_images = pcv.analyze_bound_horizontal(img, obj, mask, 1680)\n",
    "\n",
    "# There are two images returned in boundary_images. Plot them both out \n",
    "white_background_horiz_img, horiz_bound_img = boundary_images\n",
    "pcv.plot_image(white_background_horiz_img)\n",
    "pcv.plot_image(horiz_bound_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine color properties: Histograms, Color Slices and Pseudocolored Images, output color analyzed images (optional)\n",
    "\n",
    "# Inputs:\n",
    "#   rgb_img - RGB image data\n",
    "#   mask - Binary mask of selected contours \n",
    "#   bins - Number of color bins (0-256)\n",
    "#   hist_plot_type - None (default), 'all', 'rgb', 'lab', or 'hsv'\n",
    "#                    This is the data to be printed to the SVG histogram file  \n",
    "color_header, color_data, color_histogram = pcv.analyze_color(img, kept_mask, 256, 'all')\n",
    "\n",
    "# Since color_histogram is a plotnine ggplot we can plot it to the screen without pcv.plot_image\n",
    "color_histogram.save(os.path.join(params.debug_outdir, 'analyze_color_hist.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide plant object into twenty equidistant bins and assign pseudolandmark points based upon their \n",
    "# actual (not scaled) position. Once this data is scaled this approach may provide some information \n",
    "# regarding shape independent of size.\n",
    "\n",
    "top_x, bottom_x, center_v_x = pcv.x_axis_pseudolandmarks(obj, mask, img)\n",
    "\n",
    "top_y, bottom_y, center_v_y = pcv.y_axis_pseudolandmarks(obj, mask, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write shape and color data to results file\n",
    "# Result file will go to the notebooks folder! \n",
    "result = open(args.result,\"a\")\n",
    "result.write('\\t'.join(map(str,shape_header)))\n",
    "result.write(\"\\n\")\n",
    "result.write('\\t'.join(map(str,shape_data)))\n",
    "result.write(\"\\n\")\n",
    "for row in shape_img:  \n",
    "    result.write('\\t'.join(map(str,row)))\n",
    "    result.write(\"\\n\")\n",
    "result.write('\\t'.join(map(str,color_header)))\n",
    "result.write(\"\\n\")\n",
    "result.write('\\t'.join(map(str,color_data)))\n",
    "result.write(\"\\n\")\n",
    "for row in color_img:\n",
    "    result.write('\\t'.join(map(str,row)))\n",
    "    result.write(\"\\n\")\n",
    "result.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}