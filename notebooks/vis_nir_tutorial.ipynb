{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VIS/NIR Tutorial \n",
    "\n",
    "For dual VIS/NIR pipelines, a visible image is used to identify an image mask for the plant material.\n",
    "The [get nir](get_nir.md) function is used to get the NIR image that matches the VIS image (must be in same folder,\n",
    "with similar naming scheme), then functions are used to size and place the VIS image mask over the NIR image.\n",
    "This allows two workflows to be done at once and also allows plant material to be identified in low-quality images.\n",
    "We do not recommend this approach if there is a lot of plant movement between capture of NIR and VIS images.\n",
    "\n",
    "To run a VIS/NIR pipeline over a single VIS image there are two required inputs:\n",
    "\n",
    "1.  **Image:** Images can be processed regardless of what type of VIS camera was used (high-throughput platform, digital camera, cell phone camera).\n",
    "Image processing will work with adjustments if images are well lit and free of background that is similar in color to plant material.  \n",
    "2.  **Output directory:** If debug mode is set to 'print' output images from each intermediate step are produced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, traceback\n",
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "import string\n",
    "from plantcv import plantcv as pcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class options:\n",
    "    def __init__(self):\n",
    "        self.image = \"img/tutorial_images/vis_nir/VIS_SV_image.jpg\"\n",
    "        self.debug = \"plot\"\n",
    "        self.writeimg= False \n",
    "        self.result = \"./vis_nir_tutorial_results\"\n",
    "        self.coresult = \"./vis_nir_coresult\"\n",
    "        self.outdir = \".\"\n",
    "# Get options\n",
    "args = options()\n",
    "\n",
    "# Set debug to the global parameter \n",
    "pcv.params.debug = args.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image (sometimes you need to run this line twice to see the image) \n",
    "img, path, filename = pcv.readimage(args.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB to HSV and extract the saturation channel\n",
    "\n",
    "# Inputs:\n",
    "#   rgb_image - RGB image data \n",
    "#   channel - Split by 'h' (hue), 's' (saturation), or 'v' (value) channel\n",
    "s = pcv.rgb2gray_hsv(img, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the Saturation image\n",
    "\n",
    "# Inputs:\n",
    "#   gray_img - Grayscale image data \n",
    "#   threshold- Threshold value (between 0-255)\n",
    "#   max_value - Value to apply above threshold (255 = white) \n",
    "#   object_type - 'light' (default) or 'dark'. If the object is lighter than the background then standard threshold is done.\n",
    "#                 If the object is darker than the background then inverse thresholding is done. \n",
    "s_thresh = pcv.threshold.binary(s, 50, 255, 'light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Blur\n",
    "\n",
    "# Inputs: \n",
    "#   gray_img - Grayscale image data \n",
    "#   ksize - Kernel size (integer or tuple), (ksize, ksize) box if integer input,\n",
    "#           (n, m) box if tuple input \n",
    "s_mblur = pcv.median_blur(s_thresh, 5)\n",
    "s_cnt = pcv.median_blur(s_thresh, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB to LAB and extract the blue channel\n",
    "\n",
    "# Input:\n",
    "#   rgb_img - RGB image data \n",
    "#   channel- Split by 'l' (lightness), 'a' (green-magenta), or 'b' (blue-yellow) channel\n",
    "b = pcv.rgb2gray_lab(img, 'b')\n",
    "\n",
    "# Threshold the blue image\n",
    "b_thresh = pcv.threshold.binary(b, 129, 255, 'light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the thresholded saturation and blue-yellow images\n",
    "\n",
    "# Inputs: \n",
    "#   bin_img1 - Binary image data to be compared to bin_img2\n",
    "#   bin_img2 - Binary image data to be compared to bin_img1\n",
    "bs = pcv.logical_and(s_mblur, b_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Mask (for VIS images, mask_color=white)\n",
    "\n",
    "# Inputs:\n",
    "#   rgb_img - RGB image data \n",
    "#   mask - Binary mask image data \n",
    "#   mask_color - 'white' or 'black' \n",
    "masked = pcv.apply_mask(img, bs, 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify objects\n",
    "\n",
    "# Inputs: \n",
    "#   img - RGB or grayscale image data for plotting \n",
    "#   mask - Binary mask used for detecting contours \n",
    "id_objects,obj_hierarchy = pcv.find_objects(masked, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ROI\n",
    "\n",
    "# Inputs: \n",
    "#   x - The x-coordinate of the upper left corner of the rectangle \n",
    "#   y - The y-coordinate of the upper left corner of the rectangle \n",
    "#   h - The height of the rectangle \n",
    "#   w - The width of the rectangle \n",
    "#   img - RGB or grayscale image to plot the ROI on \n",
    "roi1, roi_hierarchy = pcv.roi.rectangle(800,450,920,700, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which objects to keep\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data to display kept objects on \n",
    "#   roi_type - 'cutto' or 'partial' => include objects that are partially inside or overlapping with the ROI \n",
    "#   roi_contour - contour of ROI, output from pcv.roi.rectangle in this case\n",
    "#   object_contour - contour of objects, output from pcv.roi.rectangle in this case \n",
    "#   obj_hierarchy - heirarch of objects, output from pcv.find_objects function \n",
    "roi_objects, hierarchy, kept_mask, obj_area = pcv.roi_objects(img,'partial',roi1,roi_hierarchy,id_objects,obj_hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object combine kept objects\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data for plotting \n",
    "#   contours - Contour list \n",
    "#   hierarchy - Contour hierarchy array \n",
    "obj, mask = pcv.object_composition(img, roi_objects, hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Analysis ################  \n",
    "  \n",
    "# Find shape properties, output shape image (optional) \n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   obj- Single or grouped contour object\n",
    "#   mask - Binary image mask to use as mask for moments analysis \n",
    "# Returns:\n",
    "#   shape_header, shape_data, and analysis_images (an array containing the original image with shape\n",
    "#   data plotted on it, and the mask) \n",
    "shape_header, shape_data, analysis_images = pcv.analyze_object(img, obj, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for sharp angles \n",
    "\n",
    "# Inputs:\n",
    "#   obj - A contour of the plant object \n",
    "#   window - The pre and post point distances on which to calculate \n",
    "#            the angle of the focal point on which to calculate \n",
    "#            the angle\n",
    "#   thresh - Threshold to set for acuteness\n",
    "#   sep - The number of contour points to search within for the \n",
    "#         most acute value \n",
    "#   img - RGB or grayscale image \n",
    "acute_points_list = pcv.acute_vertex(obj, 30, 25, 100, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can automatically crop an image to a contour \n",
    "\n",
    "# Inputs: \n",
    "#   img - RGB or grayscale image data\n",
    "#   object - Contour of target object \n",
    "#   padding_x - Padding in the x direction (default padding_x=0)\n",
    "#   padding_y - Padding in the y direction (default padding_y=0)\n",
    "#   color - Either 'black' (default) or 'white'\n",
    "cropped_img = pcv.auto_crop(img, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape properties relative to user boundary line \n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   obj - Single or grouped contour object \n",
    "#   mask - Binary mask of selected contours \n",
    "#   line_position - Position of boundary line (a value of 0 would draw a line \n",
    "#                   through the bottom of the image) \n",
    "boundary_header, boundary_data, boundary_images_h = pcv.analyze_bound_horizontal(img, obj, mask, 700)\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   obj - Single or grouped contour object \n",
    "#   mask - Binary mask of selected contours \n",
    "#   line_position - Position of boundary line (a value of 0 would draw a line \n",
    "#                   through the left of the image) \n",
    "boundary_header, boundary_data, boundary_images_v = pcv.analyze_bound_vertical(img, obj, mask, 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine color properties: Histograms, Color Slices and Pseudocolored Images, output color analyzed images (optional)\n",
    "\n",
    "# Inputs:\n",
    "#   rgb_img - RGB image data\n",
    "#   mask - Binary mask of selected contours \n",
    "#   bins - Number of color bins (0-256)\n",
    "#   hist_plot_type - None (default), 'all', 'rgb', 'lab', or 'hsv'\n",
    " \n",
    "color_header, color_data, color_histogram = pcv.analyze_color(img, kept_mask, 256, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write shape and color data to results file\n",
    "pcv.print_results(filename=args.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps are to get the matching NIR image, resize, and place the VIS mask over it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coresult is set within the second jupyter line of code\n",
    "if args.coresult is not None:\n",
    "    nirpath = pcv.get_nir(path,filename)\n",
    "    nir, path1, filename1 = pcv.readimage(nirpath)\n",
    "    nir2 = cv2.imread(nirpath,0)\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image to resize\n",
    "#   resize_x - resize number in the x dimension\n",
    "#   resize_y - resize number in the y dimension \n",
    "nmask = pcv.resize(mask, 0.28,0.28)\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   mask - Binary image to be used as a mask \n",
    "#   x - Amount to push in the vertical direction\n",
    "#   y - Amount to push in the horizontal direction\n",
    "#   v_pos - Push from the 'top' (default) or 'bottom' in the vertical direction\n",
    "#   h_pos - Push from the 'right' (default) or 'left' in the horizontal direction \n",
    "newmask = pcv.crop_position_mask(nir, nmask, 34, 7, \"top\", \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find objects in the new mask \n",
    "\n",
    "nir_objects, nir_hierarchy = pcv.find_objects(nir, newmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine objects\n",
    "\n",
    "nir_combined, nir_combinedmask = pcv.object_composition(nir, nir_objects, nir_hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the NIR intensity \n",
    "\n",
    "# Inputs: \n",
    "#   gray_img - 8 or 16-bit grayscale image data \n",
    "#   mask - Binary mask made from selected contours \n",
    "#   bins - Number of classes to divide spectrum into\n",
    "#   histplot - If True then plots histogram of intensity values, (default False) \n",
    "nhist_header, nhist_data, nir_hist = pcv.analyze_nir_intensity(nir2, nir_combinedmask, 256, histplot=True)\n",
    "\n",
    "# Plot the NIR histogram to the screen (since the hist is made with plotnine ggplot, no need to use pcv.plot_image) \n",
    "nir_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the shape of the object \n",
    "nshape_header, nshape_data, nir_images = pcv.analyze_object(nir2, nir_combined, nir_combinedmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The print_results function will take the measurements stored when running any (or all) of these functions, format, \n",
    "# and print an output text file for data analysis. The Outputs class stores data whenever any of the following functions\n",
    "# are ran: analyze_bound_horizontal, analyze_bound_vertical, analyze_color, analyze_nir_intensity, analyze_object, \n",
    "# fluor_fvfm, report_size_marker_area, watershed. If no functions have been run, it will print an empty text file \n",
    "pcv.print_results(filename='vis_nir_tutorial_results.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
