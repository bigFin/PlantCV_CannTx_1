{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NIR Tutorial \n",
    "\n",
    "When starting an image-based phenotyping project it is important to consider what the end goals of the project are.\n",
    "This is important because the goals of the project will determine the the camera type, imaging layout, and will help to \n",
    "guide downstream analysis. If it was \n",
    "an experiment focused on drought of maize plants and your goal was to get information about water content of plants you\n",
    "might want to take side-view and top-view images of a single plant with a near-infrared camera.\n",
    "\n",
    "To run a NIR pipeline over a single NIR image there are three required inputs:\n",
    "\n",
    "1.  **Image:** NIR images are grayscale matrices (1 signal dimension).\n",
    "In principle, image processing will work on any grayscale image with adjustments if images are well lit and\n",
    "there is appreciable contrast difference between the object of interest and the background.\n",
    "2.  **Output directory:** If debug mode is set to 'print' output images from each intermediate step are produced.\n",
    "3.  **Image of estimated background:** Right now this is hardcoded into the pipeline (different background at each zoom level) and not implemented as an argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Import PlantCV \n",
    "from plantcv import plantcv as pcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class options:\n",
    "    def __init__(self):\n",
    "        self.image = \"img/tutorial_images/nir/original_image.jpg\"\n",
    "        self.debug = \"plot\"\n",
    "        self.writeimg= False\n",
    "        self.result = \"./nir_tutorial_results\"\n",
    "        self.outdir = \".\"\n",
    "        \n",
    "# Get options\n",
    "args = options()\n",
    "\n",
    "# Set debug to the global parameter \n",
    "pcv.params.debug = args.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "img, path, filename = pcv.readimage(args.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the background image \n",
    "img_bkgrd = cv2.imread(\"img/tutorial_images/nir/background_average.jpg\", flags=0)\n",
    "# Manually plot the background image out since not using a PlantCV function \n",
    "pcv.plot_image(img_bkgrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the background image from the image with the plant. \n",
    "\n",
    "# Inputs: \n",
    "#   gray_img1 - Grayscale image data from which gray_img2 will be subtracted\n",
    "#   gray_img2 - Grayscale image data which will be subtracted from gray_img1\n",
    "bkg_sub_img = pcv.image_subtract(img, img_bkgrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is very low contrast in the subtracted image produced \n",
    "# above so normalizing the histogram might help.\n",
    "\n",
    "# Inputs:\n",
    "#   gray_img - Grayscale image data \n",
    "equalized_img = pcv.hist_equalization(bkg_sub_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are often multiple ways to process images. There is also \n",
    "# a background subtraction function made that creates a binary \n",
    "# image from performing background subtraction on the foreground\n",
    "\n",
    "# Inputs:\n",
    "#   foreground_image - RGB or grayscale image data\n",
    "#   background_image - RGB or grayscale image data \n",
    "fgmask = pcv.background_subtraction(img, img_bkgrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the image of interest using the two-sided cv2.inRange function (keep what is between 50-190) \n",
    "bkg_sub_thres_img = cv2.inRange(bkg_sub_img, 50, 190)\n",
    "\n",
    "# Since we are using an OpenCV function, we need to make it print \n",
    "if args.debug == 'print': \n",
    "    pcv.print_image(bkg_sub_thres_img, 'bkgrd_sub_thres.png')\n",
    "elif args.debug == 'plot':\n",
    "    pcv.plot_image(bkg_sub_thres_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplace filtering (identify edges based on 2nd derivative)\n",
    "\n",
    "# Inputs:\n",
    "#   gray_img - Grayscale image data \n",
    "#   k - Aperture size used to calculate the second derivative filter, \n",
    "#       specifies the size of the kernel (must be an odd integer)\n",
    "#   scale - Scaling factor applied (multiplied) to computed Laplacian values \n",
    "#           (scale = 1 is unscaled) \n",
    "lp_img = pcv.laplace_filter(img, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lapacian image sharpening, this step will enhance the darkness of the edges detected\n",
    "lp_shrp_img = pcv.image_subtract(img, lp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel filtering\n",
    "# 1st derivative sobel filtering along horizontal axis, kernel = 1)\n",
    "\n",
    "# Inputs: \n",
    "#   gray_img - Grayscale image data \n",
    "#   dx - Derivative of x to analyze \n",
    "#   dy - Derivative of y to analyze \n",
    "#   k - Aperture size used to calculate 2nd derivative, specifies the size of the kernel and must be an odd integer\n",
    "# NOTE: Aperture size must be greater than the largest derivative (k > dx & k > dy) \n",
    "sbx_img = pcv.sobel_filter(img, 1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st derivative sobel filtering along vertical axis, kernel = 1)\n",
    "\n",
    "sby_img = pcv.sobel_filter(img, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another function similar to the sobel filter is the scharr \n",
    "# filter. Depending on the image, one method might work a bit\n",
    "# better than the other. Note dx+dy==1 must be satisfied. \n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   dx - Derivative of x to analyze (0 or 1)\n",
    "#   dy - Derivative of y to analyze (0 or 1)\n",
    "#   scale - scaling factor applied (multiplied) to computed \n",
    "#           Scharr values (scale = 1 is unscaled)\n",
    "scharrx_img = pcv.scharr_filter(img, 1, 0, 1)\n",
    "scharry_img = pcv.scharr_filter(img, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the effects of both x and y filters through matrix addition\n",
    "# This will capture edges identified within each plane and emphasize edges found in both images\n",
    "\n",
    "# Inputs:\n",
    "#   gray_img1 - Grayscale image data to be added to gray_img2\n",
    "#   gray_img2 - Grayscale image data to be added to gray_img1\n",
    "sb_img = pcv.image_add(sbx_img, sby_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a lowpass (blurring) filter to smooth sobel image\n",
    "\n",
    "# Inputs:\n",
    "#   gray_img - Grayscale image data \n",
    "#   ksize - Kernel size (integer or tuple), (ksize, ksize) box if integer input,\n",
    "#           (n, m) box if tuple input \n",
    "mblur_img = pcv.median_blur(sb_img, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the image so our background is white \n",
    "\n",
    "# Inputs:\n",
    "#   gray_img - Grayscale image data \n",
    "mblur_invert_img = pcv.invert(mblur_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the smoothed sobel image with the laplacian sharpened image\n",
    "# combines the best features of both methods as described in \"Digital Image Processing\" by Gonzalez and Woods pg. 169\n",
    "\n",
    "edge_shrp_img = pcv.image_add(mblur_invert_img, lp_shrp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform thresholding to generate a binary image\n",
    "\n",
    "# Inputs: \n",
    "#   gray_img - Grayscale image data \n",
    "#   threshold - Threshold value (0-255)\n",
    "#   max_value - Value to apply above the threshold (255 = white)\n",
    "#   object_type - 'light' (default) or 'dark'. If the object is lighter than \n",
    "#                 the background then standard thresholding is done. If the \n",
    "#                 object is darker than the background then inverse thresholding. \n",
    "tr_es_img = pcv.threshold.binary(edge_shrp_img, 165, 255, 'dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fill function to get rid of small salt&pepper noise in the image \n",
    "\n",
    "# Inputs: \n",
    "#   bin_img - Binary image data \n",
    "#   size - Minimum object area size in pixels (must be an integer), and smaller objects will be filled\n",
    "f_img = pcv.fill(tr_es_img, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is another PlantCV function that can help reduce background \n",
    "# noise, and can be used with `pcv.dilate` to avoid losing plant \n",
    "\n",
    "# Inputs:\n",
    "#   gray_img - Grayscale (usually binary) image data \n",
    "#   kernel - An integer that is used to build a kernel x kernel \n",
    "#            matrix using np.ones. Must be greater than 1 to have an effect \n",
    "#   i - An integer for the number of iterations \n",
    "eroded_img = pcv.erode(tr_es_img, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring the two object identification approaches together.\n",
    "# Using a logical OR combine object identified by background subtraction and the object identified by derivative filter.\n",
    "\n",
    "# Inputs: \n",
    "#   bin_img1 - Binary image data to be compared in bin_img2\n",
    "#   bin_img2 - Binary image data to be compared in bin_img1\n",
    "comb_img = pcv.logical_or(f_img, bkg_sub_thres_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get masked image, Essentially identify pixels corresponding to plant and keep those.\n",
    "\n",
    "# Inputs: \n",
    "#   rgb_img - RGB image data \n",
    "#   mask - Binary mask image data \n",
    "#   mask_color - 'black' or 'white'\n",
    "masked_erd = pcv.apply_mask(img, comb_img, 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to remove the edges of the image, we did that by generating a set of rectangles to mask the edges\n",
    "# img is (254 X 320)\n",
    "# Mask for the bottom of the image\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   p1 - Point at the top left corner of the rectangle (tuple)\n",
    "#   p2 - Point at the bottom right corner of the rectangle (tuple) \n",
    "#   color 'black' (default), 'gray', or 'white'\n",
    "masked1, box1_img, rect_contour1, hierarchy1 = pcv.rectangle_mask(img, (110,185), (215,252))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask for the left side of the image\n",
    "\n",
    "masked2, box2_img, rect_contour2, hierarchy2 = pcv.rectangle_mask(img, (1,1), (60,252))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask for the right side of the image\n",
    "\n",
    "masked3, box3_img, rect_contour3, hierarchy3 = pcv.rectangle_mask(img, (240,1), (320,254))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the bottom edge\n",
    "\n",
    "masked4, box4_img, rect_contour4, hierarchy4 = pcv.rectangle_mask(img, (0,251), (320,254))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine boxes to filter the edges and car out of the photo\n",
    "\n",
    "# Inputs: \n",
    "#   bin_img1 - Binary image data to be compared in bin_img2\n",
    "#   bin_img2 - Binary image data to be compared in bin_img1\n",
    "bx12_img = pcv.logical_and(box1_img, box2_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx123_img = pcv.logical_and(bx12_img, box3_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx1234_img = pcv.logical_and(bx123_img, box4_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_masked_img = pcv.apply_mask(masked_erd, bx1234_img, 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify objects\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data for plotting\n",
    "#   mask - Binary mask used for detecting contours\n",
    "id_objects,obj_hierarchy = pcv.find_objects(img, edge_masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ROI\n",
    "\n",
    "# Inputs: \n",
    "#   x - The x-coordinate of the upper left corner of the rectangle \n",
    "#   y - The y-coordinate of the upper left corner of the rectangle \n",
    "#   h - The height of the rectangle \n",
    "#   w - The width of the rectangle \n",
    "#   img - RGB or grayscale image to plot the ROI on \n",
    "roi1, roi_hierarchy= pcv.roi.rectangle(x=100, y=45, h=130, w=100, img=edge_masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which objects to keep\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data to display kept objects on \n",
    "#   roi_type - 'cutto' or 'partial' => include objexts that are partially inside or overlapping with the ROI \n",
    "#   roi_contour - contour of ROI, output from pcv.roi.rectangle in this case\n",
    "#   object_contour - contour of objects, output from pcv.roi.rectangle in this case \n",
    "#   obj_hierarchy - hierarchy of objects, output from pcv.find_objects function \n",
    "roi_objects, hierarchy5, kept_mask, obj_area = pcv.roi_objects(edge_masked_img, 'partial', roi1, roi_hierarchy, id_objects, obj_hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can perform a distance transformation on a binary image \n",
    "# that can assist with object segmentation \n",
    "\n",
    "# Inputs:\n",
    "#   bin_img - Binary image data \n",
    "#   distance_type - Type of distance. It can be CV_DIST_L1, CV_DIST_L2 , \n",
    "#                   or CV_DIST_C which are 1,2 and 3 respectively.\n",
    "#   mask_size - Size of the distance transform mask. It can be 3, 5, \n",
    "#               or CV_DIST_MASK_PRECISE (the latter option is only supported \n",
    "#               by the first function). In case of the CV_DIST_L1 or \n",
    "#               CV_DIST_C distance type, the parameter is forced to 3 because \n",
    "#               a 3 by 3 mask gives the same result as 5 by 5 or any larger aperture.\n",
    "dist_img = pcv.distance_transform(kept_mask, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the image to have 3 channels \n",
    "rgb_img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Use the object_composition function to outline the plant \n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data for plotting \n",
    "#   contours - Contour list \n",
    "#   hierarchy - Contour hierarchy array \n",
    "grp_object, img_mask = pcv.object_composition(rgb_img, roi_objects, hierarchy5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform the analysis of pixelwise signal value and object shape attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform signal analysis\n",
    "\n",
    "# Inputs: \n",
    "#   gray_img - 8 or 16-bit grayscale image data \n",
    "#   mask - Binary mask made from selected contours \n",
    "#   bins - Number of classes to divide the spectrum into \n",
    "#   histplot - If True, plots the histogram of intensity values \n",
    "nir_header, nir_data, nir_hist = pcv.analyze_nir_intensity(img, kept_mask, 256, histplot=True)\n",
    "\n",
    "# Plot out the NIR histogram (since the hist is made with plotnine ggplot, no need to use pcv.plot_image) \n",
    "nir_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#     gray_img - Grayscale image data\n",
    "#     mask - Binary mask (optional) \n",
    "#     cmap - Colormap\n",
    "#     min_value - Minimum value for range of interest\n",
    "#     max_value - Maximum value for range of interest\n",
    "#     path - Path for location for saving the image\n",
    "\n",
    "# Pseudocolor the NIR grayscale image \n",
    "pseudocolored_img = pcv.pseudocolor(gray_img=img, mask=kept_mask, cmap='viridis')\n",
    "\n",
    "# Plot out the pseudocolored image to the screen\n",
    "pcv.plot_image(pseudocolored_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform shape analysis\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   obj- Single or grouped contour object\n",
    "#   mask - Binary image mask to use as mask for moments analysis \n",
    "# Returns:\n",
    "#   shape_header, shape_data, and analysis_images (an array containing the original image with shape\n",
    "#   data plotted on it, and the mask) \n",
    "shape_header, shape_data, shape_imgs = pcv.analyze_object(rgb_img, grp_object, img_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write shape and nir data to results file\n",
    "result=open(args.result,\"a\")\n",
    "result.write('\\t'.join(map(str,shape_header)))\n",
    "result.write(\"\\n\")\n",
    "result.write('\\t'.join(map(str,shape_data)))\n",
    "result.write(\"\\n\")\n",
    "for row in shape_img:\n",
    "    result.write('\\t'.join(map(str,row)))\n",
    "    result.write(\"\\n\")\n",
    "result.write('\\t'.join(map(str,nir_header)))\n",
    "result.write(\"\\n\")\n",
    "result.write('\\t'.join(map(str,nir_data)))\n",
    "result.write(\"\\n\")\n",
    "for row in nir_img:\n",
    "    result.write('\\t'.join(map(str,row)))\n",
    "    result.write(\"\\n\")\n",
    "result.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
