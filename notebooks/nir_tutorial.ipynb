{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NIR Tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images in line \n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import cv2\n",
    "# Set the desired figure size to get printed out \n",
    "matplotlib.rcParams[\"figure.figsize\"] = (8.0, 8.0)\n",
    "# Import PlantCV \n",
    "from plantcv import plantcv as pcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class options:\n",
    "    def __init__(self):\n",
    "        self.image = \"img/tutorial_images/nir/original_image.jpg\"\n",
    "        self.debug = \"plot\"\n",
    "        self.writeimg= False\n",
    "        self.result = \"./nir_tutorial_results\"\n",
    "        self.outdir = \".\"\n",
    "        \n",
    "# Get options\n",
    "args = options()\n",
    "\n",
    "# Set debug to the global parameter \n",
    "pcv.params.debug = args.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "img, path, filename = pcv.readimage(args.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the background image \n",
    "img_bkgrd = cv2.imread(\"img/tutorial_images/nir/background_average.jpg\", flags=0)\n",
    "# Manually plot the background image out since not using a PlantCV function \n",
    "pcv.plot_image(img_bkgrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the background image from the image with the plant. \n",
    "\n",
    "# Inputs: \n",
    "#   gray_img1 - Grayscale image data from which gray_img2 will be subtracted\n",
    "#   gray_img2 - Grayscale image data which will be subtracted from gray_img1\n",
    "bkg_sub_img = pcv.image_subtract(img, img_bkgrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the image of interest using the two-sided cv2.inRange function (keep what is between 50-190) \n",
    "bkg_sub_thres_img = cv2.inRange(bkg_sub_img, 50, 190)\n",
    "\n",
    "# Since we are using an OpenCV function, we need to make it print \n",
    "if args.debug == 'print': \n",
    "    pcv.print_image(bkg_sub_thres_img, 'bkgrd_sub_thres.png')\n",
    "elif args.debug == 'plot':\n",
    "    pcv.plot_image(bkg_sub_thres_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplace filtering (identify edges based on 2nd derivative)\n",
    "\n",
    "# Inputs:\n",
    "#   gray_img - Grayscale image data \n",
    "#   k - Aperture size used to calculate the second derivative filter, \n",
    "#       specifies the size of the kernel (must be an odd integer)\n",
    "#   scale - Scaling factor applied (multiplied) to computed Laplacian values \n",
    "#           (scale = 1 is unscaled) \n",
    "lp_img = pcv.laplace_filter(img, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lapacian image sharpening, this step will enhance the darkness of the edges detected\n",
    "lp_shrp_img = pcv.image_subtract(img, lp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel filtering\n",
    "# 1st derivative sobel filtering along horizontal axis, kernel = 1)\n",
    "\n",
    "# Inputs: \n",
    "#   gray_img = Grayscale image data \n",
    "#   dx - Derivative of x to analyze \n",
    "#   dy - Derivative of y to analyze \n",
    "#   k - Aperture size used to calculate 2nd derivative, specifies the size of the kernel and must be an odd integer\n",
    "# NOTE: Aperture size must be greater than the largest derivative (k > dx & k > dy) \n",
    "sbx_img = pcv.sobel_filter(img, 1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st derivative sobel filtering along vertical axis, kernel = 1)\n",
    "\n",
    "sby_img = pcv.sobel_filter(img, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the effects of both x and y filters through matrix addition\n",
    "# This will capture edges identified within each plane and emphasize edges found in both images\n",
    "\n",
    "# Inputs:\n",
    "#   gray_img1 - Grayscale image data to be added to gray_img2\n",
    "#   gray_img2 - Grayscale image data to be added to gray_img1\n",
    "sb_img = pcv.image_add(sbx_img, sby_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a lowpass (blurring) filter to smooth sobel image\n",
    "\n",
    "# Inputs:\n",
    "#   gray_img - Grayscale image data \n",
    "#   ksize - Kernel size (integer or tuple), (ksize, ksize) box if integer input,\n",
    "#           (n, m) box if tuple input \n",
    "mblur_img = pcv.median_blur(sb_img, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the image so our background is white \n",
    "\n",
    "# Inputs:\n",
    "#   gray_img - Grayscale image data \n",
    "mblur_invert_img = pcv.invert(mblur_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the smoothed sobel image with the laplacian sharpened image\n",
    "# combines the best features of both methods as described in \"Digital Image Processing\" by Gonzalez and Woods pg. 169\n",
    "\n",
    "edge_shrp_img = pcv.image_add(mblur_invert_img, lp_shrp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform thresholding to generate a binary image\n",
    "\n",
    "# Inputs: \n",
    "#   gray_img - Grayscale image data \n",
    "#   threshold - Threshold value (0-255)\n",
    "#   max_value - Value to apply above the threshold (255 = white)\n",
    "#   object_type - 'light' (default) or 'dark'. If the object is lighter than \n",
    "#                 the background then standard thresholding is done. If the \n",
    "#                 object is darker than the background then inverse thresholding. \n",
    "tr_es_img = pcv.threshold.binary(edge_shrp_img, 145, 255, 'dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do erosion with a 3x3 kernel\n",
    "\n",
    "# Inputs: \n",
    "#   gray_img - Grayscale (usually binary) image data \n",
    "#   kernel - An odd integer that is used to build a kernel x kernel matrix\n",
    "#            using np.ones. Must be greater than 1 to have an effect. \n",
    "#   i - An integer for the number of iterations, i.e. the number of consecutive\n",
    "#       filtering passes \n",
    "e1_img = pcv.erode(tr_es_img, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring the two object identification approaches together.\n",
    "# Using a logical OR combine object identified by background subtraction and the object identified by derivative filter.\n",
    "\n",
    "# Inputs: \n",
    "#   bin_img1 - Binary image data to be compared in bin_img2\n",
    "#   bin_img2 - Binary image data to be compared in bin_img1\n",
    "comb_img = pcv.logical_or(e1_img, bkg_sub_thres_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get masked image, Essentially identify pixels corresponding to plant and keep those.\n",
    "\n",
    "# Inputs: \n",
    "#   rgb_img - RGB image data \n",
    "#   mask - Binary mask image data \n",
    "#   mask_color - 'black' or 'white'\n",
    "masked_erd = pcv.apply_mask(img, comb_img, 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to remove the edges of the image, we did that by generating a set of rectangles to mask the edges\n",
    "# img is (254 X 320)\n",
    "# Mask for the bottom of the image\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   p1 - Point at the top left corner of the rectangle (tuple)\n",
    "#   p2 - Point at the bottom right corner of the rectangle (tuple) \n",
    "#   color 'black' (default), 'gray', or 'white'\n",
    "masked1, box1_img, rect_contour1, hierarchy1 = pcv.rectangle_mask(img, (120,184), (215,252))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask for the left side of the image\n",
    "\n",
    "masked2, box2_img, rect_contour2, hierarchy2 = pcv.rectangle_mask(img, (1,1), (85,252))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask for the right side of the image\n",
    "\n",
    "masked3, box3_img, rect_contour3, hierarchy3 = pcv.rectangle_mask(img, (240,1), (318,252))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the edges\n",
    "\n",
    "masked4, box4_img, rect_contour4, hierarchy4 = pcv.rectangle_mask(img, (1,1), (318,252))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine boxes to filter the edges and car out of the photo\n",
    "\n",
    "bx12_img = pcv.logical_or(box1_img, box2_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx123_img = pcv.logical_or(bx12_img, box3_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx1234_img = pcv.logical_or(bx123_img, box4_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert this mask and then apply it the masked image.\n",
    "\n",
    "inv_bx1234_img = pcv.invert(bx1234_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_masked_img = pcv.apply_mask(masked_erd, inv_bx1234_img, 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify objects\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data for plotting\n",
    "#   mask - Binary mask used for detecting contours\n",
    "id_objects,obj_hierarchy = pcv.find_objects(edge_masked_img, inv_bx1234_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ROI\n",
    "\n",
    "# Inputs: \n",
    "#   x - The x-coordinate of the upper left corner of the rectangle \n",
    "#   y - The y-coordinate of the upper left corner of the rectangle \n",
    "#   h - The height of the rectangle \n",
    "#   w - The width of the rectangle \n",
    "#   img - RGB or grayscale image to plot the ROI on \n",
    "roi1, roi_hierarchy= pcv.roi.rectangle(x=100, y=100, h=200, w=200, img=edge_masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which objects to keep\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data to display kept objects on \n",
    "#   roi_type - 'cutto' or 'partial' => include objexts that are partially inside or overlapping with the ROI \n",
    "#   roi_contour - contour of ROI, output from pcv.roi.rectangle in this case\n",
    "#   object_contour - contour of objects, output from pcv.roi.rectangle in this case \n",
    "#   obj_hierarchy - heirarch of objects, output from pcv.find_objects function \n",
    "roi_objects, hierarchy5, kept_mask, obj_area = pcv.roi_objects(edge_masked_img, 'partial', roi1, roi_hierarchy, id_objects, obj_hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the image to have 3 channels \n",
    "rgb_img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Use the object_composition function to outline the plant \n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data for plotting \n",
    "#   contours - Contour list \n",
    "#   hierarchy - Contour hierarchy array \n",
    "grp_object, img_mask = pcv.object_composition(rgb_img, roi_objects, hierarchy5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform the analysis of pixelwise signal value and object shape attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform signal analysis\n",
    "\n",
    "# Inputs: \n",
    "#   gray_img - 8 or 16-bit grayscale image data \n",
    "#   mask - Binary mask made from selected contours \n",
    "#   bins - Number of classes to divide the spectrum into \n",
    "#   hisplot - If True, plots the histogram of intensity values \n",
    "#   filename - Name for output images \n",
    "nir_header, nir_data, nir_img = pcv.analyze_nir_intensity(img, kept_mask, 256, args.outdir + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform shape analysis\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   obj- Single or grouped contour object\n",
    "#   mask - Binary image mask to use as mask for moments analysis \n",
    "#   filename - False (default) or image name. If defined, then print image\n",
    "shape_header, shape_data, shape_img = pcv.analyze_object(rgb_img, grp_object, img_mask, args.outdir + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write shape and nir data to results file\n",
    "result=open(args.result,\"a\")\n",
    "result.write('\\t'.join(map(str,shape_header)))\n",
    "result.write(\"\\n\")\n",
    "result.write('\\t'.join(map(str,shape_data)))\n",
    "result.write(\"\\n\")\n",
    "for row in shape_img:\n",
    "    result.write('\\t'.join(map(str,row)))\n",
    "    result.write(\"\\n\")\n",
    "result.write('\\t'.join(map(str,nir_header)))\n",
    "result.write(\"\\n\")\n",
    "result.write('\\t'.join(map(str,nir_data)))\n",
    "result.write(\"\\n\")\n",
    "for row in nir_img:\n",
    "    result.write('\\t'.join(map(str,row)))\n",
    "    result.write(\"\\n\")\n",
    "result.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}